{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098af403-2e5d-46f9-a322-b6b6b1a4d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ea5603-dc0c-4a62-9b18-98afce0ce705",
   "metadata": {},
   "outputs": [],
   "source": [
    "### custome functions \n",
    "def modify_race_col(row) -> int:\n",
    "    '''\n",
    "    logic to make a compariable filed to HISPALLP_C in the post 2019 datasets\n",
    "    '''\n",
    "    HISPAN_I = row['HISPAN_I']\n",
    "    RACERPI2 = row['RACERPI2']\n",
    "    \n",
    "    if HISPAN_I != 12:\n",
    "        return 1\n",
    "\n",
    "    match RACERPI2:\n",
    "        case 1:\n",
    "            return 2\n",
    "        case 2:\n",
    "            return 3\n",
    "        case 3:\n",
    "            return 5\n",
    "        case 5:\n",
    "            return 99\n",
    "        case 6:\n",
    "            return 7\n",
    "        case _:\n",
    "            return 0\n",
    "\n",
    "def create_data_file_layout_dict() -> dict:\n",
    "    '''\n",
    "    intake text file that filed layouts for .dat \n",
    "    files\n",
    "    '''\n",
    "    layout_dict = dict()\n",
    "\n",
    "    with open('data/file_layouts.txt') as f:\n",
    "        for line in f:\n",
    "            clean_line = line.replace('\\n','').replace('\\t','').split(',')\n",
    "            layout_dict[int(clean_line[0])] = [int(x) for x in clean_line[1:]]\n",
    "\n",
    "    return layout_dict\n",
    "\n",
    "\n",
    "def create_dat_file_vars() -> dict:\n",
    "    #get the field layout for each file\n",
    "    layout_dict = create_data_file_layout_dict()\n",
    "\n",
    "    #the fields we will select and for what year\n",
    "    dat_fields = [1,2,5,6,8,9,12,13,14,17]\n",
    "    data_2011_2014_fields = [29]\n",
    "    data_2008_2010_fields = [28]\n",
    "    data_2005_2007_fields = [25]\n",
    "\n",
    "    #the renames for each file\n",
    "    dat_file_renames = {\n",
    "        1: 'SRVY_YR',\n",
    "        2: 'HHX',\n",
    "        5: 'FMX',\n",
    "        6: 'FPX',\n",
    "        8: 'WTFA_SC',\n",
    "        9: 'REGION',\n",
    "        12: 'SEX',\n",
    "        13: 'HISPAN_I',\n",
    "        14: 'RACERPI2',\n",
    "        17: 'AGE_P',\n",
    "    }\n",
    "    dat_file_2011_2014_renames = {29: 'ADD2'}\n",
    "    dat_file_2008_2010_renames = {28: 'ADD2'}\n",
    "    dat_file_2005_2007_renames = {25: 'ADD2'}\n",
    "    \n",
    "    \n",
    "    #create final dic used to process the .dat files\n",
    "    dat_files = {\n",
    "        2014:{\n",
    "            'file_nm':'data/child14.dat',\n",
    "            'file_layout':layout_dict[2014],\n",
    "            'select_fields':dat_fields + data_2011_2014_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2011_2014_renames\n",
    "        },\n",
    "        2013:{\n",
    "            'file_nm':'data/child13.dat',\n",
    "            'file_layout':layout_dict[2013],\n",
    "            'select_fields': dat_fields + data_2011_2014_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2011_2014_renames  \n",
    "        },\n",
    "        2012:{\n",
    "            'file_nm':'data/child12.dat',\n",
    "            'file_layout':layout_dict[2012],\n",
    "            'select_fields': dat_fields + data_2011_2014_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2011_2014_renames  \n",
    "        },\n",
    "        2011:{\n",
    "            'file_nm':'data/child11.dat',\n",
    "            'file_layout':layout_dict[2011],\n",
    "            'select_fields': dat_fields + data_2011_2014_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2011_2014_renames  \n",
    "        },\n",
    "        2010:{\n",
    "            'file_nm':'data/child10.dat',\n",
    "            'file_layout':layout_dict[2010],\n",
    "            'select_fields': dat_fields + data_2008_2010_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2008_2010_renames  \n",
    "        },  \n",
    "        2009:{\n",
    "            'file_nm':'data/child09.dat',\n",
    "            'file_layout':layout_dict[2009],\n",
    "            'select_fields': dat_fields + data_2008_2010_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2008_2010_renames  \n",
    "        },  \n",
    "        2008:{\n",
    "            'file_nm':'data/child08.dat',\n",
    "            'file_layout':layout_dict[2008],\n",
    "            'select_fields': dat_fields + data_2008_2010_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2008_2010_renames  \n",
    "        },  \n",
    "        2007:{\n",
    "            'file_nm':'data/child07.dat',\n",
    "            'file_layout':layout_dict[2007],\n",
    "            'select_fields': dat_fields + data_2005_2007_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2005_2007_renames  \n",
    "        },  \n",
    "        2006:{\n",
    "            'file_nm':'data/child06.dat',\n",
    "            'file_layout':layout_dict[2006],\n",
    "            'select_fields': dat_fields + data_2005_2007_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2005_2007_renames  \n",
    "        }, \n",
    "        2005:{\n",
    "            'file_nm':'data/child05.dat',\n",
    "            'file_layout':layout_dict[2005],\n",
    "            'select_fields': dat_fields + data_2005_2007_fields,\n",
    "            'rename_fiedls': dat_file_renames | dat_file_2005_2007_renames  \n",
    "        },  \n",
    "    } \n",
    "\n",
    "    return dat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25c081b-cf9e-4b50-8aed-8c428bd81211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create file list for processing\n",
    "post_19_files = ('data/child23.csv','data/child22.csv','data/child21.csv','data/child20.csv','data/child19.csv',)\n",
    "\n",
    "#pre_19 import vars\n",
    "pre_19_csv = ('data/child18.csv','data/child17.csv','data/child16.csv','data/child15.csv',)\n",
    "pre_19_renames = {\n",
    "    'WTFA_SC':'WTFA_C',\n",
    "    'SEX':'SEX_C',\n",
    "    'AGE_P':'AGEP_C',\n",
    "    'ADD2':'ADHDEV_C',\n",
    "    'ADD2N':'ADHDNW_C',\n",
    "}\n",
    "\n",
    "\n",
    "dat_files_2005_2014 = create_dat_file_vars()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0dce75-f111-4d51-ab46-bc117111821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     WTFA_SC  REGION  SEX  HISPAN_I  RACERPI2  AGE_P  ADD2\n",
      "HHX SRVY_YR FMX FPX                                                       \n",
      "13  2014    1   3       6039       4    1         3         1      0   NaN\n",
      "20  2014    1   4       3145       4    2        12         1      2   2.0\n",
      "25  2014    1   4       5497       2    2        12         1     16   2.0\n",
      "29  2014    1   5        592       2    2        12         1      7   2.0\n",
      "34  2014    1   2       6553       1    2        12         2     12   2.0\n",
      "115390\n"
     ]
    }
   ],
   "source": [
    "### load 2005 to 2014 data\n",
    "dat_df = pd.DataFrame()\n",
    "\n",
    "for key, value in dat_files_2005_2014.items():\n",
    "    df = pd.read_fwf(value['file_nm'],widths=value['file_layout'],header=None)\n",
    "    df = df[value['select_fields']]\n",
    "    df = df.rename(columns=value['rename_fiedls'])\n",
    "    dat_df = pd.concat([dat_df,df])\n",
    "\n",
    "\n",
    "dat_df.set_index(['HHX','SRVY_YR','FMX','FPX'],inplace=True)\n",
    "print(dat_df.head())\n",
    "print(len(dat_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c1dd46-a5be-492e-999a-08a6fca901ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40512\n"
     ]
    }
   ],
   "source": [
    "### load 2015 to 2018\n",
    "df_2015_2018 = pd.DataFrame()\n",
    "\n",
    "for file in pre_19_csv:\n",
    "\n",
    "    if file == 'data/child15.csv':\n",
    "        cols = ['SRVY_YR','HHX','FMX','FPX','WTFA_SC','REGION','SEX',\n",
    "                'AGE_P','HISPAN_I','RACERPI2','ADD2',\n",
    "                ]\n",
    "    else:\n",
    "        cols = ['SRVY_YR','HHX','FMX','FPX','WTFA_SC','REGION','SEX',\n",
    "                'AGE_P','HISPAN_I','RACERPI2','ADD2','ADD2N'\n",
    "                ]\n",
    "    \n",
    "    df = pd.read_csv(file,\n",
    "                     sep=',',\n",
    "                     header=0,\n",
    "                     index_col = ['HHX','SRVY_YR','FMX','FPX'],\n",
    "                     usecols=cols\n",
    "                    )\n",
    "\n",
    "    df_2015_2018 = pd.concat([df_2015_2018,df])\n",
    "\n",
    "##print the length\n",
    "print(len(df_2015_2018))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d11a10e-13d0-4140-8fa4-7ea2e82b5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([], names=['HHX', 'SRVY_YR', 'FMX', 'FPX'])\n",
      "155902\n"
     ]
    }
   ],
   "source": [
    "### merge 2015 to 2018 and 2005 to 2014 dataframes and strt to do clean up\n",
    "df_2005_2018 = pd.concat([dat_df,df_2015_2018]).reset_index()\n",
    "df_2005_2018.set_index(['HHX','SRVY_YR','FMX','FPX'], inplace=True)\n",
    "\n",
    "\n",
    "duplicates = df_2005_2018.index.duplicated()\n",
    "print(df_2005_2018.index[duplicates])\n",
    "print(len(df_2005_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24f37858-8795-4e84-acf9-b6505ca076b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "                     WTFA_C  REGION  SEX_C  AGEP_C  ADHDEV_C  ADHDNW_C  \\\n",
      "HHX SRVY_YR FMX FPX                                                      \n",
      "13  2014    1   3      6039       4      1       0       NaN       NaN   \n",
      "20  2014    1   4      3145       4      2       2       2.0       NaN   \n",
      "25  2014    1   4      5497       2      2      16       2.0       NaN   \n",
      "29  2014    1   5       592       2      2       7       2.0       NaN   \n",
      "34  2014    1   2      6553       1      2      12       2.0       NaN   \n",
      "\n",
      "                     HISPALLP_C  \n",
      "HHX SRVY_YR FMX FPX              \n",
      "13  2014    1   3             1  \n",
      "20  2014    1   4             2  \n",
      "25  2014    1   4             2  \n",
      "29  2014    1   5             2  \n",
      "34  2014    1   2             3  \n"
     ]
    }
   ],
   "source": [
    "##create HISPALLP_C\n",
    "df_2005_2018['HISPALLP_C'] = df_2005_2018.apply(modify_race_col, axis=1)\n",
    "print(df_2005_2018['HISPALLP_C'].isnull().sum())\n",
    "\n",
    "##drop columns 'HISPAN_I','RACERPI2' as they are not needed.\n",
    "df_2005_2018.drop(['HISPAN_I','RACERPI2'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "##renaming columns to help combined\n",
    "df_2005_2018 = df_2005_2018.rename(columns=pre_19_renames)\n",
    "print(df_2005_2018.head())\n",
    "print(len(df_2005_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4488585c-9170-43a2-a432-dcb1471039a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         HISPALLP_C  REGION  SEX_C  AGEP_C  MHRX_C  RX12M_C  \\\n",
      "HHX     SRVY_YR FMX FPX                                                       \n",
      "H045277 2023    1   1             3       3      2      14     2.0        2   \n",
      "H021192 2023    1   1             2       3      2      11     2.0        2   \n",
      "H025576 2023    1   1             2       3      1      15     2.0        1   \n",
      "H058458 2023    1   1             2       3      2       8     2.0        1   \n",
      "H047432 2023    1   1             3       3      1      12     1.0        1   \n",
      "\n",
      "                         LASTDR_C  ADHDNW_C  ADHDEV_C     WTFA_C  \n",
      "HHX     SRVY_YR FMX FPX                                           \n",
      "H045277 2023    1   1           1       NaN       2.0  13012.875  \n",
      "H021192 2023    1   1           1       NaN       2.0  16680.509  \n",
      "H025576 2023    1   1           1       NaN       2.0   5404.923  \n",
      "H058458 2023    1   1           1       NaN       2.0   9758.143  \n",
      "H047432 2023    1   1           1       1.0       1.0  20404.132  \n",
      "38400\n",
      "MultiIndex([], names=['HHX', 'SRVY_YR', 'FMX', 'FPX'])\n"
     ]
    }
   ],
   "source": [
    "## create the final df with the post 2019 files\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for file in post_19_files:\n",
    "    df = pd.read_csv(file,\n",
    "                     sep=',',\n",
    "                     header=0,\n",
    "                     index_col = ['HHX','SRVY_YR'],\n",
    "                     usecols = ['HHX','SRVY_YR','WTFA_C','REGION',\n",
    "                                'SEX_C','AGEP_C','HISPALLP_C',\n",
    "                                'ADHDEV_C','ADHDNW_C','LASTDR_C',\n",
    "                                'RX12M_C','MHRX_C',\n",
    "                               ]\n",
    "                    )\n",
    "    final_df = pd.concat([final_df,df])\n",
    "\n",
    "\n",
    "\n",
    "final_df['FMX'] = 1\n",
    "final_df['FPX'] = 1\n",
    "\n",
    "final_df.reset_index(inplace=True)\n",
    "final_df.set_index(['HHX','SRVY_YR','FMX','FPX'],inplace=True)\n",
    "\n",
    "duplicates = final_df.index.duplicated()\n",
    "\n",
    "\n",
    "print(final_df.head())\n",
    "print(len(final_df))\n",
    "print(final_df.index[duplicates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de30d52d-b9ee-4036-a48f-74430df8870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         HISPALLP_C  REGION  SEX_C  AGEP_C  MHRX_C  RX12M_C  \\\n",
      "HHX     SRVY_YR FMX FPX                                                       \n",
      "H045277 2023    1   1             3       3      2      14     2.0      2.0   \n",
      "H021192 2023    1   1             2       3      2      11     2.0      2.0   \n",
      "H025576 2023    1   1             2       3      1      15     2.0      1.0   \n",
      "H058458 2023    1   1             2       3      2       8     2.0      1.0   \n",
      "H047432 2023    1   1             3       3      1      12     1.0      1.0   \n",
      "\n",
      "                         LASTDR_C  ADHDNW_C  ADHDEV_C     WTFA_C  \n",
      "HHX     SRVY_YR FMX FPX                                           \n",
      "H045277 2023    1   1         1.0       NaN       2.0  13012.875  \n",
      "H021192 2023    1   1         1.0       NaN       2.0  16680.509  \n",
      "H025576 2023    1   1         1.0       NaN       2.0   5404.923  \n",
      "H058458 2023    1   1         1.0       NaN       2.0   9758.143  \n",
      "H047432 2023    1   1         1.0       1.0       1.0  20404.132  \n",
      "194302\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.concat([final_df,df_2005_2018]).reset_index()\n",
    "final_df.set_index(['HHX','SRVY_YR','FMX','FPX'],inplace=True)\n",
    "print(final_df.head())\n",
    "print(len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfb10f9a-804a-4b61-8be7-8d72e633e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export the file for use latter\n",
    "final_df.to_csv('data/final_data_set.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
